\chapter{CloudVision分布式机器视觉库}
\label{cha:distributed_vision_library}
本章介绍CloudVision实现的分布式机器视觉的算法，
这些算法作为CloudVision的核心分布式机器视觉算法库。
用户可以通过CloudVision的控制与管理层，直接提交
器视觉库的任务。另外机器视觉库作为一个参考实现，让
用户更深了解怎么写自己的CloudVision分布式机器视觉的程序。

\begin{figure}[h]
  \centering
    \includegraphics[width=0.99\textwidth]{computer-vision-library}
  \caption{CloudVision分布式机器视觉库实现的阶段}
  \label{fig:computer-vision-library}
\end{figure}
在图\ref{fig:computer-vision-library}描述在CloudVision机器视觉库实现的阶段，首先需要
在数据集做预处理，然后在处理好的数据抽取特征，然后从特征描述子转码成图像表示，最后用图像表示
和分类器分类数据。
先介在章\ref{sec:storage_format}介绍所有算法用到的存储结构，
了解到预处理的做法和结构怎么解决在大数据平台大量小文件问题。
在章\ref{sec:feature-extraction}介绍分布式特征抽取算法的实现，
介绍CloudVision提出的高效执行OpenCV的SIFT特征抽取方法。
在章\ref{sec:image-representation}介绍分布式的词典学习和
图像表示实现。
在章\ref{sec:cloudvision_classifier}介绍分布式的SVM分类器，训练
和分类实现。


\section{存储结构}
\label{sec:storage_format}
CloudVision里面的程序经常需要读写数据集，中间结果和最终结果。
为了统一化数据结果，CloudVision机器视觉库提出一个通用合适
于大数据平台的数据结构。在分布式存储面对一个问题怎么
高效读写图像数据，在章\ref{subsec:big-data-small-files}我们详细
描述该问题同时提出两个解决方法。
在章\ref{subsec:seq-file}详细介绍第一个方法，用Hadoop SequenceFile
保存大量图像文件。在章\ref{subsec:parquet}介绍一个数据格式
合适存算法的中间结果。


\subsection{大数据大量小文件问题}
\label{subsec:big-data-small-files}
机器视觉数据集包括大量的图像，每个图像文件一般在10KB到200KB以内，
直接存这些图像文件到HDFS或者Hadoop兼容文件系统存在性能和易用问题。
回顾到章\ref{subsubsec:hdfs}的HDFS介绍，Hadoop存储方式把文件分成blocks，将每个
block复制到多个datanode，默认的Block大小是128MB。如果
直接保存图像文件到HDFS会造成，每个文件分成一个block，
而且这个block没满。很多没满的block造成两个的问题：
\begin{enumerate}
  \item HDFS的Namenode内存容易满

        HDFS保存所有文件的元数据在Namenode的内存。如果保存海量
        文件会造成Namnode内存用满。采用S3或者Swift对象存储没有
        这个问题。

  \item 处理时候IO性能问题
        
        MapReduce和Spark的任务，读数据的时候会通过一次IO请求
        读取一个block，将整个block执行用户提供map函数，执行任务。如果
        每个block数据小，但是block很多，需要大量的处理任务造成大量的数据量小的IO请求。
        HDFS和大部分对象存储的延迟比较高，因此大量传输大小小的IO请求造成
        总体IO性能很差。
\end{enumerate}


通过包装多个图片到一个大文件，将大文件保存到HDFS或者对象存储，
这样一个block会包括多个图像，可以解决上面两个问题。
Hadoop的SequenceFile是一个可以包装多个二进制文件到一个大文件。
目前在CloudVision通过两个方式解决高性能
批量处理小文件的问题：SequenceFiles和
Apache Parquet的存储格式。我们用SequenceFile作为
图片存储，Parquet提供中间结果存储结构比如图片特征。


\subsection{基于SequenceFile存储大量图片}
\label{subsec:seq-file}
Hadoop的SequenceFile格式使用Key/Value对保存数据，Key和Value支持
多种数据类型，包括二进制类型。跟其他Key/Value数据结构不一样，
SequenceFile不支持按Key寻找，编辑或者删除数据。SequenceFile只支持
追加数据。SequenceFile有一个Header主要描述Key和Value数据类型和压缩配置，
然后有Key/Value对数据记录。SequenceFile的好处是MapReduce或者Spark程序，
可以并行读取SequenceFile的不同的block，提高并行处理性能。

CloudVision使用SequenceFile保存大量的图片，Key是一个
String用来保存图片文件名字，Value是一个Array[Bytes]用来保存
图片的内容。

\begin{figure}[h]
  \centering
    \includegraphics[width=0.98\textwidth,trim=1 1 4 1,clip]{cloudvision-seqfile}
  \caption{CloudVision 保存图片的SequenceFile格式和用法}
  \label{fig:cloudvision-seqfile}
\end{figure}

在图\ref{fig:cloudvision-seqfile}有一个例子保存整个ImageNet2015数据集。
黄色表示Key保存文件名字：1.jpg和蓝色表示图片的裸的bytes。SequenceFile可以有
$N$个条目。

为了容易让用户转换和上传数据集，CloudVision自开发了一个工具。
在算法\ref{lst:uploadseqfile}提供了几行工具主要代码。
工具的输入是一个图片目录和输出目录，它从图片目录读取所有
文件文件名和内容，创建出来一个SequenceFile在输出目录，
将每个图片文件保存到SequenceFile里。比如用户可以这样
调用工具：
upload\_to\_seqfile /home/sam/imagenet2014 swift://spark.swift/imagenet2014.hseq，
会将用户本地/home/sam/imagenet2014图片目录上传到Swift的对象存储保存一个SequenceFile，
Swift里面文件名是imagenet2014.hseq。

\begin{lstlisting}[language=Java,
                   basicstyle=\tiny,
                   showstringspaces=false,
                   caption={UploadToSequenceFile工具},
                   label={lst:uploadseqfile}]
Path outputPath = new Path(outputPath);
writer = SequenceFile.createWriter(conf, SequenceFile.Writer.file(seqFilePath), 
            SequenceFile.Writer.keyClass(Text.class),
            SequenceFile.Writer.valueClass(BytesWritable.class));
for (File file : imageFiles) {
    byte buffer[] = Files.toByteArray(file);
    writer.append(new Text(file.getName()), new BytesWritable(buffer));
}
writer.close();
\end{lstlisting}

在后续的Spark任务可以通过SparkContext.sequenceFile直接读取SequenceFile。
Spark会自动把Key,Value Pairs做成一个RDD。在章\ref{sec:feature-extraction}
会有详细的例子使用图片的SequenceFile抽取特征。

\subsection{基于Parquet通用数据结构}
\label{subsec:parquet}
Parquet是提供一个通用的数据列式存储。列式存储
按列保存数据，特别合适在批量处理使用。CloudVision
主要用Parquet来保存所有处理的结果，比如从图片抽取的
特征或者图像表示。
在CloudVision选上了Parquet的原因有：
\begin{itemize}
  \item 通用性 \\
        不同的处理平台都
        支持Parquet的格式包含Spark, Hadoop Map/Reduce和Cascading。
  \item 高效I/O \\
        因为度数据的时候不需要扫描。Parquet列式存储底层使用blocks保存，
        可以按整个block做一次IO请求读取block里面所有数据。另外可以
        只选需要读取的列，降低需要读取的大小。
  \item 高效压缩 \\
        Parquet的压缩编码能减少存储使用的大小。
  \item Spark SQL的DataFrame兼容性 \\
        Spark natively支持Parquet的格式。通过Spark SQL可以直接
        读取Parquet文件转成DataFrame，同样DataFrame可以直接
        写成Parquet文件。
\end{itemize}



\section{特征抽取}
\label{sec:feature-extraction}
在章\ref{intro:image_features}我们介绍了主流的特征，基于深度学习的CNN特征在很多应用场景能达到最好的结果，
但是SIFT还是最常用的人工特征。在机器视觉库，我们先实现了基于SIFT人工特征的特征抽取，
在后续的版本也会支深度学习特征的抽取和模型学习。
SIFT的局部特征算法有两部分，特征关键点检测和特征描述子。在关键点检测过程找出图像的关键点，然后
将每个关键点使用特征描述算法计算出一个128维的描述向量。已经有多个开源软件实现SIFT算法，
包括OpenCV，VLFeat，ImageJ和ezSIFT。OpenCV也支持很多其他人工特征包含SURF和其他图像处理的算法，
因此我们选了集成OpenCV到CloudVision，使可能从Spark程序调用OpenCV，实现分布式SIFT特征抽取和OpenCV其他
算法。

在前期的调研，网上没找到材料教怎么在Spark怎么调用OpenCV，
在自己实现过程也碰到了几个问题，可能这些问题造成晚上几乎没材料。
从Spark调用OpenCV面对的问题：
\begin{itemize}
  \item 从Spark调用OpenCV问题 \\
        Spark提供Java，Scala和Python的language bindings。OpenCV也提供C++，Java和Python的API。
        需要考虑到哪个语言更合适还有在每个服务器装上OpenCV，保证Spark可以调用OpenCV的接口。
        Java problem
  \item 从SequenceFile高效读取图像到OpenCV需要格式的问题 \\
        OpenCV一般从一个文件目录读取图像，在大数据结构所有图像在SequenceFile里面，读的时候直接把图像读到内存。
        在网上的方式都先把图像写到一个暂时的文件然后从暂时文件读到OpenCV的图像Image class，但是这个方式带来Disk IO的平静。
        我们需要高效从大数据数据结构读取图像到内存，将在内存里的图像直接用OpenCV抽取特征。
  \item Spark的单任务开销 \\
        每个Spark任务有开销，因此如果每个任务运行时间很段，这开销会显著，造成一个性能问题。
\end{itemize}


\begin{figure}[h]
  \centering
    \includegraphics[width=0.66\textwidth]{cloudvision-feature-extraction}
  \caption{CloudVision在Spark集群特征抽取的方式。}
  \label{fig:cloudvision-feature-extraction}
\end{figure}
通过描述CloudVision具体的基于Spark和OpenCV特征抽取方式，说明CloudVision怎么解决上面定义的问题。
在开发过程中我们发现OpenCV的Java
API不支持OpenCV Contrib，但是SIFT属于OpenCV Contrib的特征，因此在特征抽取我们用了Spark和OpenCV
的Python接口。在用PySpark的时候碰了PYTHONPATH没有包含了OpenCV，但是通过调试与特殊配置解决了问题。

在图\ref{fig:cloudvision-feature-extraction}可以看到简单化的Spark特征抽取程序的流程。
第一步程序调用读取sequenceFile的函数，提供sequenceFile的目录和partition数，
从Hadoop兼容文件系统读取SequenceFile，把SequenceFile划分到partitions，
partition分布到Spark集群的executors的内存里。sequenceFile函数返回一个Spark的RRD object。

第二布是用返回的RDD object的mapPartition函数，提供extractFeatures的作为mapPartition的函数。这样每个集群里
的Spark Executor会在本地的partition执行extractFeatures函数。extractFeatures函数用OpenCV把图像
转换图像特征。mapPartitions放回一个新的RDD，新的RDD数据有图像文件名字和图像特征。
在算法\ref{lst:opencv-extract-features}可以看到extractFeatures的核心代码，
特点在于从一个Python byte array转换到一个OpenCV的image，在第二行我们把
在内存里的imgbytes转换成一个numpy.array叫nparr，第三行从nparr都城一个
OpenCV的image object可以同来抽特征。在算法\ref{lst:opencv-extract-features}
的代码描述了怎么高效从大数据结构化的数据抽取特征。
\begin{lstlisting}[language=Python,
                   basicstyle=\small,
                   showstringspaces=false,
                   caption={OpenCV从内存读取图像抽取特征},
                   label={lst:opencv-extract-features}]
imgfilename, imgbytes = imgfile_imgbytes
nparr = np.fromstring(buffer(imgbytes), np.uint8)
img = cv2.imdecode(nparr, 0)
if feature_name in ["surf", "SURF"]:
    extractor = cv2.SURF()
elif feature_name in ["sift", "SIFT"]:
    extractor = cv2.SIFT()
kp, descriptors = extractor.detectAndCompute(img, None)
return [(imgfilename, descriptors)]
\end{lstlisting}

第三步把特征的RDD写到持久存储。把Spark的RDD转换成一个Spark的DataFrame object，然后用DataFrame写到
Hadoop兼容的文件系统，比如HDFS，S3或者Swift。DataFrame的结构使用图像名字作为地一个columnn，
特征作为第二个column，特征是一个Array of Doubles。

为了解决Spark单任务开销问题，我们在第二比使用了mapPartitions。在读取的时候保证每个partition包括
多张图片。通过了解到数据集和服务器数量可以选择合适的partition数。定义为集群总体CPU核数为$c$，数据集
大小用为$s$单元使用MB，推荐partition数为$p$，那通过在\ref{eq:partition_recommendation}的公式可以推荐partition数。
\begin{equation} \label{eq:partition_recommendation}
p = max(c * 3, \frac{s}{32})
\end{equation}
如果数据集小，会按照CPU核数推荐partition数，在数据集大但是CPU核数小的情况还是保证每个partition不会大于32MB。



\section{特征编码与图像表示}
\label{sec:image-representation}
在章\ref{subsubsec:feature-encoding}我们介绍了BoW, Fisher Vector和VLAD的特征转码与图像表示的方法。
介绍的特装转码与图像表示方法同样都有一个Visual Dictionary（词典）学习过程，BoW使用KMeans学习，
Fisher Vector使用Gausian Mixture Model(GMM)学习，VLAD可以选使用KMeans或者GMM学习。
学习词典后，用词典分配每个特征描述子的点到一个codeword（码字），这过程叫Feature Encoding（特征转码），然后通过
pooling把所有点计算在一起得到一个图像表示。

为了演示特征编码与图像表示过程，CloudVision实现了BoW + Sum pooling的特征转码与图像表示，
主要原因其他方法是基于BoW的改进而且实现相对复杂。在章\ref{subsec:dict-learning}介绍CloudVision
BoW词典学习的实现方法，然后在章\ref{subsec:feature-encoding}介绍CloudVision的BoW特征转码与pooling
实现方法。

\subsection{词典学习}
\label{subsec:dict-learning}
BoW词典学习使用KMeans聚类算法找出数据集的类似的点。KMeans找出的$K$个类据，每个聚类
描述一个codeword（码字）。
假设使用SIFT特征生产词典，会找出$K$个128维度的向量，每个向量表示一个码字。
CloudVision实现的KMeans词典学习方式支持多种特征不限于128维度的数据集。

在写词典学习的程序中面对了两个问题。第一，KMeans是一个迭代算法如果每次
重新读取或者计算特征会带来性能瓶颈。第二，Spark MLlib的KMeans算法
不能直接用在一个X x 128的矩阵，需要换成一样大小的响亮。
% optionally add picture of learning algorithm

CloudVision词典学习过程序需要提供几个参数：选词典的大小$K$，特征文件目录，最大迭代数，KMeans模型目录。
执行CloudVision字典学习程序会在提供特征文件目录的数据找出$K$个类的词典，如果没有找到局部最优最多会迭代用户
提供的最大迭代数。在算法\ref{lst:kmeans-dictionary}列出了CloudVision字典学习核心代码，
第一行分布式读取特征到Spark集群的每台executor，第二行用flatMap获取features列子和把X x Y的的矩阵变成X个1 x Y的向量然后缓存到Spark内存，
第三行用Spark MLlib提供的分布式KMeans算法找出K个聚类，第五行保存结构到分布式存储。
\begin{lstlisting}[language=Python,
                   basicstyle=\small,
                   showstringspaces=false,
                   numbers=left,
                   caption={词典学习核心代码},
                   label={lst:kmeans-dictionary}]
features = sqlContext.read.parquet(feature_parquet_path)
flattened_features = features.flatMap(lambda x: x['features']).cache()
model = KMeans.train(flattened_features, k, maxIterations=maxIter,
                     initializationMode="random")
model.save(sc, kmeans_model_path)
\end{lstlisting}
第二行的代码解决上面定义的两个问题，通过Spark RDD的cache函数缓存到内存决迭第一个代算法瓶颈问题，
通过flatMap转换一样大小响亮解决第二个问题。


\subsection{特征转码与pooling}
\label{subsec:feature-encoding}
学了词典以后我们可以用它把图像的特征转码成最终图像表示。
CloudVision目前实现了最简单的基于BoW特征转码然后用Sum pooling作出直方图。
这个过程把每个特征关键点的描述子分配到字典里的一个码字，
然后通过sum pooling统计一个1 x $K$个向量叫BoW图像表示。
BoW表示向量指数表示第$K$个码字在图像出现了多少次，
BoW表示是码字的直方图。

在CloudVision的特征转码与pooling面对了一个值得提的问题，
如果分布式在每个Spark executor执行特征转码都需要同一个字典，
这个词典每次从Hadoop兼容文件系统读取变成了一个IO性能瓶颈。
下面介绍CloudVision特征转码用到Spark的broadcast功能解决此问题。


\begin{figure}[h]
  \centering
    \includegraphics[width=0.66\textwidth]{cloudvision-feature-encoding}
  \caption{CloudVision在Spark集群实现BoW特征转码与表示。}
  \label{fig:cloudvision-feature-encoding}
\end{figure}
在图\ref{fig:cloudvision-feature-encoding}可以看到基于Spark分布式方式
实现特征转码与表示。第一步从Hadoop兼容存储读取Parquet格式的图像的特征和KMeans model，这里KMeans model
是在章\ref{subsec:dict-learning}学习的词典(Visual Codebook)。因为每个执行特征转码的Spark Executor都需要
用这个词典，我们一次性通过Spark Broadcast变量把词典提前播放的每个Spark Executor的内存，避免每个节点单独从Hadoop
兼容文件系统读取词典。\cite{spark-programming-guide}

有了词典可以高效分布式执行特征转码过程，使用Spark分布式map操作执行
BoW表示函数，BoW函数把每个图像特征矩阵变成一个1 x $K$个响亮表示码字的直方图。
在算法\ref{lst:feature-encoding}可以看到BoW函数核心代码。
第一行建立Spark KMeansModel。第二行建立一个1 x $K$的向量用来保存BoW表示。
第三行建立一个循环遍历特征描述矩阵的每个关键点描述子。
第四行用词典找出离关键点最近的码字。第六行在BoW表示向量
增加相应的码字的个数。
\begin{lstlisting}[language=Python,
                   basicstyle=\small,
                   numbers=left,
                   showstringspaces=false,
                   caption={BoW特征转码核心代码},
                   label={lst:feature-encoding}]
model = KMeansModel(dictionary)
bow = np.zeros(len(dictionary))
for keypoint_descriptor in feature_matrix:
    k = model.predict(keypoint_descriptor)
    if pooling = "sum":
        bow[k] += 1
return bow
\end{lstlisting}

所有图像map到了图像表示后，使用Parquet格式保存保存到Hadoop兼容的文件系统。这个过程
会分布式从每个Spark executor同时写本地处理的BoW表示写到持久存储。


\section{分类器}
\label{sec:cloudvision_classifier}
CloudVision实现了主流的SVM分类其，这里说明分布式实现方式和碰到的问题。
在章\ref{subsubsec:classifier}介绍了多个分类器，但是发现SVM是最常用。
无论在人工特征或者深度学习的特征SVM都可以达到最先进的结果。
所有监督机器学习都采用一个学习过程，学习用有标签的数据训练出来一个模型，有了模型后才可以用
它类未标签的数据。


Spark的MLlib已经包括一个binary(single class) SVM分布式分类器实现，
为了不要重复发明轮子CloudVision基于MLlib现有SVM实现开发。
在基于Spark MLlib的SVM开发面对了两个问题：
\begin{itemize}
  \item Spark MLlib只提供binary(single) classifier SVM不符合多数机器视觉应用场景。Binary SVM限于分类两种类型，
        但是大部分的机器视觉场景有超过两个类型的分类需求。
  \item 基于Spark MLlib监督机器学习算法需要用它定义的格式，训练数据需要是一个Spark LabeledPoint类型的RDD。
        需要分布式预处理特征BoW表示数据。
\end{itemize}

CloudVision分类器使用Scala实现，因为Scala可以更紧密的扩展MLlib原有的机器学习方法。
为了训练分类器先需要预处理数据，在本章\ref{subsec:classifier-preprocessing}描述CloudVision分类器预处理数据(preprocessing)的实现方法，
解决需要符合Spark MLlib格式数据的问题。然后在\ref{subsec:classifier-training}介绍基于处理好的训练数据训练多类别分布式SVM训练实现方法。
在图\ref{fig:cloudvision-classifier}可以看到预处理和多类别SVM的实现方式。
训练完了可以用多类别的SVM模型分类无知类别的数据，在\ref{subsec:classifier-label}描述CloudVision多类别SVM分类的实现。

\begin{figure}[h]
  \centering
    \includegraphics[width=0.60\textwidth]{cloudvision-classifier}
  \caption{CloudVision预处理和训练分类器实现}
  \label{fig:cloudvision-classifier}
\end{figure}



\subsection{数据预处理}
\label{subsec:classifier-preprocessing}
数据预处理需要从数据集获取类别ID和特征表示，组成一个Spark的LabeledPoint。
Spark的LabeledPoint格式需要两个变量：类别ID(label)和特征向量(features)。
类别ID的变量数据类型是Double，必须从零开始算每个整数表述一个独立的类别。
特征向量变量的数据类型是Spark的org.apache.spark.mllib.linalg.Vector。

从数据集获取类别ID，在多数数据集可以使用图像文件名字，
比如在Caltech-256数据集每个图像文件名的格式是\{classid\}\_\{imgid\}.jpg，
这样可以通过一个regex(正则表达式)从文件名找出类型，
在Caltech256可以用这个正则表达式\verb|(\d+)_\d+.jpg|
取出类型ID。

在图\ref{fig:cloudvision-classifier}可以看到预处理实现方式，
先从Hadoop兼容文件系统读取BoW特征向量和文件名字的DataFrame。
然后通过一个分布式map操作，用上面描述的方式把文件名字和BoW变成
一个RDD of LabeledPoint。



\subsection{训练}
\label{subsec:classifier-training}
训练多类别的SVM分类器方法是每个类别独立训练一个二类分类器。
假设有$N$个类别，那需要训练$1..N$个二类（binary）SVM分类器。
在训练第$i$个列别的时候，先需要把数据集里所有不等于$i$的类别设置为$0$，
然后将数据集里所有等于$i$的列别设置为$1$。这样我们把问题变成一个
普通的二类SVM分类器问题。在图\ref{fig:cloudvision-classifier}可以但到最后部分训练的过程。
在算法\ref{lst:classifier-training}是用pseudocode描述实现方式。
\begin{lstlisting}[language=Python,
                   basicstyle=\small,
                   numbers=left,
                   showstringspaces=false,
                   caption={SVM多类别分类器训练pseudocode},
                   label={lst:classifier-training}]
svm_classifiers = []
for classid in classes:
    binary_label_features = features_bow.map(to_binary_label)
    svm_classifiers.append(SVMWithSGD.train(binary_label_features))
\end{lstlisting}



\subsection{分类}
\label{subsec:classifier-label}
分类过程把无知类别的数据填上类别。多类别SVM分类器，使用$N$个类别的二类分类器
，这$N$个分类器是基于\ref{subsec:classifier-training}训练的，
$N$个列别的分类器中得分最高的分类器是预测到的类别。
\begin{lstlisting}[language=Python,
                   basicstyle=\small,
                   numbers=left,
                   showstringspaces=false,
                   caption={SVM多类别分类器分类pseudocode},
                   label={lst:classifier-training}]
scores = []
for classifier in svm_classifiers:
    score, classid = classifier.predict(features_bow)
    scores.append( (score, classid) )

return scores.sortByScore.getFirst.getClassid
\end{lstlisting}




