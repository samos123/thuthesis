\chapter{CloudVision分布式机器视觉库}
\label{cha:distributed_vision_library}
本章介绍CloudVision实现的分布式机器视觉的算法，
这些算法是CloudVision的核心分布式机器视觉算法库。
用户可以通过CloudVision的控制管理层，直接提交
器视觉库的任务。另外机器视觉库作为一个参考实现，让
用户更深入地了解怎么实现自己的CloudVision分布式机器视觉程序。

\begin{figure}[h]
  \centering
    \includegraphics[width=0.99\textwidth]{computer-vision-library}
  \caption{CloudVision分布式机器视觉库实现过程}
  \label{fig:computer-vision-library}
\end{figure}
图\ref{fig:computer-vision-library}描述CloudVision机器视觉库实现的过程。首先需要
将数据集做预处理，然后对处理好的数据做抽取特征，第三从特征描述子转码成图像表示，最后用图像表示
和分类器分类数据。
章节\ref{sec:storage_format}介绍所有算法用到的存储结构，
了解预处理的做法和结构，怎么解决在大数据平台大量小文件的问题。
章节\ref{sec:feature-extraction}介绍分布式特征抽取算法的实现，
介绍CloudVision提出的高效执行OpenCV的SIFT特征抽取方法。
章节\ref{sec:image-representation}介绍分布式的词典学习和
图像表示实现。
章节\ref{sec:cloudvision_classifier}介绍分布式的SVM分类器，训练
和分类实现。


\section{存储结构}
\label{sec:storage_format}
CloudVision里面的程序经常需要读写数据集，中间结果和最终结果。
为了统一化数据结果，CloudVision机器视觉库提出一个通用的合适
于大数据平台的数据结构。分布式存储面对一个问题是怎么
高效读写图像数据，在章\ref{subsec:big-data-small-files}详细
描述该问题，并提出两个解决方法。
在章\ref{subsec:seq-file}详细介绍第一个方法，用Hadoop SequenceFile
保存大量图像文件。在章\ref{subsec:parquet}介绍一个
合适存算法的中间结果的数据格式。


\subsection{大数据大量小文件问题}
\label{subsec:big-data-small-files}
机器视觉数据集包括大量的图像，每个图像文件一般在10KB到200KB以内，
直接存这些图像文件到HDFS或者Hadoop兼容文件系统存在性能和易用问题。
回顾章\ref{subsubsec:hdfs}的HDFS介绍，Hadoop存储方式把文件分成blocks，将每个
block复制到多个datanode，默认的Block大小是128MB。如果
直接保存图像文件到HDFS会造成，每个文件分成一个block，
而且这个block没满。很多没满的block造成两个的问题：
\begin{enumerate}
  \item HDFS的Namenode内存容易满

        HDFS保存所有文件的元数据在Namenode的内存。如果保存海量
        文件会造成Namnode内存用满。采用S3或者Swift对象存储没有
        这个问题。

  \item 处理时候IO性能问题
        
        MapReduce和Spark的任务，读数据的时候会通过一次IO请求
        读取一个block，对整个block执行用户提供的函数。如果
        每个block数据小，但是block很多，需要大量地处理任务，造成大量的数据量小的IO请求。
        HDFS和大部分对象存储的延迟比较高，因此大量传输小的IO请求造成
        总体IO性能很差。
\end{enumerate}


通过包装多个图片到一个大文件，将大文件保存到HDFS或者对象存储，
这样一个block会包括多个图像，可以解决上面两个问题。
Hadoop的SequenceFile可以包装多个二进制文件到一个大文件。
目前在CloudVision通过两个方式解决高性能
批量处理小文件的问题：SequenceFiles和
Apache Parquet的存储格式。机器视觉库用SequenceFile作为
图片存储，Parquet提供中间结果存储结构比如图片特征。


\subsection{基于SequenceFile存储大量图片}
\label{subsec:seq-file}
Hadoop的SequenceFile格式使用Key/Value保存数据。Key和Value支持
多种数据类型，包括二进制类型。跟其他Key/Value数据结构不同，
SequenceFile不支持按Key寻找，编辑或者删除数据。SequenceFile只支持
追加数据。SequenceFile有一个Header主要描述Key和Value数据类型和压缩配置，
然后由Key/Value记录实际数据。SequenceFile的好处是MapReduce或者Spark程序，
可以并行读取SequenceFile的不同的block，提高并行处理性能。

CloudVision使用SequenceFile保存大量的图片，Key是一个
String用来保存图片文件名字，Value是一个Array[Bytes]用于保存
图片的内容。

\begin{figure}[h]
  \centering
    \includegraphics[width=0.98\textwidth,trim=1 1 4 1,clip]{cloudvision-seqfile}
  \caption{CloudVision 保存图片的SequenceFile格式和用法}
  \label{fig:cloudvision-seqfile}
\end{figure}

图\ref{fig:cloudvision-seqfile}是保存整个ImageNet2015数据集的例子。
黄色表示Key保存文件名字,蓝色表示图片的内容，以字节数组表示。SequenceFile可以有
$N$个条目。

为了让用户容易转换和上传数据集，CloudVision自开发了一个工具。
在算法\ref{lst:uploadseqfile}提供了几行工具主要代码。
工具的输入是一个图片目录和输出目录，它从图片目录读取所有
文件的文件名和内容，
将每个图片文件保存到SequenceFile里，并保存到输出目录。比如用户可以这样
调用工具：
upload\_to\_seqfile /home/sam/imagenet2014 swift://spark.swift/imagenet2014.hseq，
会将用户本地/home/sam/imagenet2014目录下的所有图片内容，输出到Swift对象存储下的一个SequenceFile，
Swift里面文件名是imagenet2014.hseq。

\begin{lstlisting}[language=Java,
                   basicstyle=\tiny,
                   showstringspaces=false,
                   caption={UploadToSequenceFile工具},
                   label={lst:uploadseqfile}]
Path outputPath = new Path(outputPath);
writer = SequenceFile.createWriter(conf, SequenceFile.Writer.file(seqFilePath), 
            SequenceFile.Writer.keyClass(Text.class),
            SequenceFile.Writer.valueClass(BytesWritable.class));
for (File file : imageFiles) {
    byte buffer[] = Files.toByteArray(file);
    writer.append(new Text(file.getName()), new BytesWritable(buffer));
}
writer.close();
\end{lstlisting}

在后续的Spark任务可以通过SparkContext.sequenceFile直接读取SequenceFile。
Spark会自动把Key,Value Pairs做成一个RDD。在章\ref{sec:feature-extraction}
详细介绍怎么使用图片的SequenceFile抽取特征。

\subsection{基于Parquet通用数据结构}
\label{subsec:parquet}
Parquet是提供一个通用的数据列式存储。列式存储
按列保存数据，特别合适批量处理使用。CloudVision
主要用Parquet来保存所有处理的结果，比如从图片抽取的
特征或者图像表示。
在CloudVision选上了Parquet的原因有：
\begin{itemize}
  \item 通用性 \\
        不同的处理平台都
        支持Parquet的格式包含Spark, Hadoop Map/Reduce和Cascading。
  \item 高效I/O \\
        因为读数据的时候不需要扫描。Parquet列式存储底层使用blocks保存，
        可以按整个block做一次IO请求读取block里面所有数据。另外可以
        只选需要读取的列，降低需要读取的大小。
  \item 高效压缩 \\
        Parquet的压缩编码能减少存储使用的大小。
  \item Spark SQL的DataFrame兼容性 \\
        Spark原生地支持Parquet格式。通过Spark SQL可以直接
        读取Parquet文件转成DataFrame，同样DataFrame可以直接
        写成Parquet文件。
\end{itemize}



\section{特征抽取}
\label{sec:feature-extraction}
在章\ref{intro:image_features}本论文介绍了主流的特征，基于深度学习的CNN特征在很多应用场景能达到最好的结果，
但是SIFT还是最常用的人工特征。目前实现了基于SIFT人工特征的特征抽取，
在后续的版本也会支持深度学习特征的抽取和模型学习。
SIFT的局部特征算法有两部分，特征关键点检测和特征描述子。在关键点检测过程找出图像的关键点，然后
将每个关键点使用特征描述算法计算出一个128维的描述向量。已经有多个开源软件实现SIFT算法，
包括OpenCV，VLFeat，ImageJ和ezSIFT。OpenCV也支持很多其他人工特征,比如SURF和其他图像处理的算法，
因此选择集成OpenCV到CloudVision。目标是从Spark程序调用OpenCV，实现分布式SIFT特征抽取和OpenCV的其他
算法。

在前期的调研，网上没找到材料教怎么在Spark怎么调用OpenCV。
在自己实现过程也碰到了几个问题，可能这些问题造成网上几乎没有这方面材料。
从Spark调用OpenCV面对的问题：
\begin{itemize}
  \item 从Spark调用OpenCV问题

        Spark提供Java，Scala和Python的language bindings。OpenCV提供C++，Java和Python的API。
        需要保证Spark的每个计算节点能够调用相应的OpenCV接口。在实现过程中发现Java的接口不全，
        OpenCV-contrib没有相应的Java接口，因此如果用Java没有提供SIFT特征抽取的接口。OpenCV官方
        在Github确认了存在这个问题。
  \item 从SequenceFile高效读取图像到OpenCV需要格式转换的问题

        OpenCV一般从一个文件目录读取图像，在大数据结构所有图像在SequenceFile里面，读的时候直接把图像读到内存。
        在网上的方式都先把图像写到一个暂时的文件然后从暂时文件读到OpenCV的图像Image class，但是这个方式带来Disk IO的瓶颈。
        所以需要高效从大数据数据结构读取图像到内存，将在内存里的图像直接用OpenCV抽取特征。

  \item Spark的单任务开销

        启动每个Spark任务有开销，因此如果每个任务运行时间很短，这个开销会很显著，造成一个性能问题。
\end{itemize}

\subsection*{算法实现}
机器视觉库分布式SIFT和SURF特征抽取实，通过Spark分布式并行执行OpenCV的SIFT算法实现。
分布式实现细节如下：
\begin{itemize}
  \item 输入和参数

        输入是一个通过在章\ref{subsec:seq-file}介绍的图像SequenceFile，
        Key是一个String数据类型保存图像名字，Value是一个Bytes Array数据类型保存图像内容。
        图像SequenceFile一般存在Hadoop兼容文件系统。

        程序接受如下的参数：
        \begin{itemize}
            \item 特征名字，String数据类型，目前只支持SIFT或者SURF。
            \item 输入图像SequenceFile目录，String数据类型，提供图像SequenceFile存储位置。
            \item 输出特征描述parquet文件目录，String数据类型，提供特征parquet文件的该存储位置。
            \item Partition数，Int数据类型，提供图像SequenceFile需要分成多少划分。
        \end{itemize}

  \item 实现方法

        \begin{figure}[h]
          \centering
            \includegraphics[width=0.76\textwidth]{cloudvision-feature-extraction}
          \caption{CloudVision在Spark集群特征抽取的方式。}
          \label{fig:cloudvision-feature-extraction}
        \end{figure}

        在图\ref{fig:cloudvision-feature-extraction}可以看到简单化的Spark特征抽取程序的流程。
        CloudVision控制管理层在处理集群自动部署好了OpenCV和Spark，保证PySpark可以调用OpenCV的
        Python接口。
        第一步程序调用读取sequenceFile的函数，提供sequenceFile的目录和partition数，
        从Hadoop兼容文件系统读取SequenceFile，把SequenceFile划分到partitions，
        partition分布到Spark集群的executors的内存里。sequenceFile函数返回一个Spark的RRD object。

        第二步用返回的RDD object的mapPartition函数，提供extractFeatures的作为mapPartition的函数。这样每个集群里
        的Spark Executor会在本地的partition执行extractFeatures函数。extractFeatures函数用OpenCV把图像
        转换图像特征。mapPartitions放回一个新的RDD，新的RDD数据有图像文件名字和图像特征。
        在算法\ref{lst:opencv-extract-features}可以看到extractFeatures的核心代码，
        特点在于从一个Python byte array转换到一个OpenCV的image，在第二行把
        在内存里的imgbytes转换成一个numpy.array叫nparr，第三行从nparr生成一个
        OpenCV的image object可以用来抽取特征。在算法\ref{lst:opencv-extract-features}
        的代码描述了怎么高效从大数据结构化的数据抽取特征。
        \begin{minipage}{\linewidth}
        \begin{lstlisting}[language=Python,
                           basicstyle=\small,
                           showstringspaces=false,
                           caption={OpenCV从内存读取图像抽取特征},
                           label={lst:opencv-extract-features}]
        imgfilename, imgbytes = imgfile_imgbytes
        nparr = np.fromstring(buffer(imgbytes), np.uint8)
        img = cv2.imdecode(nparr, 0)
        if feature_name in ["surf", "SURF"]:
            extractor = cv2.SURF()
        elif feature_name in ["sift", "SIFT"]:
            extractor = cv2.SIFT()
        kp, descriptors = extractor.detectAndCompute(img, None)
        return [(imgfilename, descriptors)]
        \end{lstlisting}
        \end{minipage}

        第三步把特征的RDD写到持久存储。把Spark的RDD转换成一个Spark的DataFrame object，然后用DataFrame写到
        Hadoop兼容的文件系统，比如HDFS，S3或者Swift。DataFrame的结构使用图像名字作为地一个columnn，
        特征作为第二个column，特征是一个Array of Doubles。


  \item 输出

        程序的输出是一个Parquet文件，里面有两列：图像名字和特征描述子向量，
        每一行表示一张图像。程序会在用户提供的存储位置保存此Parquet文件。

\end{itemize}

为了解决Spark单任务开销问题，在第二步使用了mapPartitions。在读取的时候保证每个partition包括
多张图片。根据数据集和服务器数量，可以计算合适的partition数。定义集群总体CPU核数为$c$，数据集
大小用为$s$单元使用MB，推荐partition数为$p$，那通过在\ref{eq:partition_recommendation}的公式可以推荐partition数。
\begin{equation} \label{eq:partition_recommendation}
p = max(c * 3, \frac{s}{32})
\end{equation}
如果数据集小，会按照CPU核数推荐partition数，在数据集大但是CPU核数小的情况还是保证每个partition不会大于32MB。



\section{特征编码与图像表示}
\label{sec:image-representation}
在章\ref{subsubsec:feature-encoding}介绍了特征转码和图像表示算法，
图像表示比直接原生的特征可以更好的抽象物体的特性。所以在图像分类应用中，
经常会采用特征转码和图像表示的算法。

最经典算法是在章\ref{subsubsec:feature-encoding}
介绍机器视觉的BoW特征转码和表示算法，其他GMM和VLAD算法使用
BoW的思想。该算法首先基于数据集生产一个Visual Dictionary(词典），
词典抽象图像的特点叫码字(visual codeword)，一般使用无监督机器学习算法生产词典，比如KMeans
聚类算法或者GMM算法。这第一步生产词典叫做
词典学习，第二步使用词典从图像特征转码成图像表示，不同算法
使用不同的特征转码方法。

本章描述CloudVision库的分布式BoW特征转码
与表示实现，
选择实现BoW算法原因是其他方法是基于BoW的改进，而且实现相对复杂。在章\ref{subsec:dict-learning}介绍CloudVision
BoW词典学习的实现方法，然后在章\ref{subsec:feature-encoding}介绍CloudVision的BoW特征转码
实现方法。

\subsection{词典学习}
\label{subsec:dict-learning}
BoW词典学习使用KMeans聚类算法找出数据集的类似的点。KMeans找出的$K$个类据，每个聚类
描述一个codeword（码字）。
假设使用SIFT特征生产词典，会找出$K$个128维度的向量，每个向量表示一个码字。
CloudVision实现的KMeans词典学习方式支持多种特征，不限于128维度的数据集。

在写词典学习的程序中面对了两个问题。第一，KMeans是一个迭代算法如果每次
重新读取或者计算特征会带来性能瓶颈。第二，Spark MLlib的KMeans算法
不能直接用在一个X x 128的矩阵，需要换成一样大小的向量。
% optionally add picture of learning algorithm

\subsection*{算法实现}
机器视觉库分布式词典实现，主要使用Spark分布式机器学习库的KMeans。
分布式实现细节如下：
\begin{itemize}
  \item 输入和参数

        输入是一个Parquet格式特征文件，该特征文件是用在本章\ref{sec:feature-extraction}描述的机器视觉库特征抽取程序。Parquet特征文件一般
        存在Hadoop兼容文件系统。Parquet每一行是一个图像，要求有一列叫"features"。
        程序接受的参数如下：
        \begin{itemize}
          \item 词典大小($K$)，Int数据类型，提供KMeans算法需要找出的聚类数。
          \item 最大迭代数，Int数据类型，提供KMeans最多迭代多少次。
          \item Parquet特征文件目录，String数据类型，提供特征Parquet文
                件的存储位置。
          \item KMeans模型文件目录，String数据类型，提供词典存储位置。
        \end{itemize}

  \item 实现方法

        执行CloudVision字典学习程序会在提供特征文件目录的数据找出$K$个类的词典，如果没有找到局部最优最多会迭代用户
        提供的最大迭代数。在算法\ref{lst:kmeans-dictionary}列出了CloudVision字典学习核心代码，
        第一行分布式读取特征到Spark集群的每台executor，第二行用flatMap获取features列子和把X x Y的的矩阵变成X个1 x Y的向量然后缓存到Spark内存，
        第三行用Spark MLlib提供的分布式KMeans算法找出K个聚类，第五行保存结构到分布式存储。
        \begin{lstlisting}[language=Python,
                           basicstyle=\small,
                           showstringspaces=false,
                           numbers=left,
                           caption={词典学习核心代码},
                           label={lst:kmeans-dictionary}]
        features = sqlContext.read.parquet(feature_parquet_path)
        flattened_features = features.flatMap(lambda x: x['features']).cache()
        model = KMeans.train(flattened_features, k, maxIterations=maxIter,
                             initializationMode="random")
        model.save(sc, kmeans_model_path)
        \end{lstlisting}
        第二行解决上面定义的两个问题:通过Spark RDD的cache函数缓存到内存决迭第一个代算法瓶颈问题;
        通过flatMap转换一样大小向量解决第二个问题。


  \item 输出

        词典学习程序的输出是一个KMeans模型，里面保存$K$个聚类信息，保存到用户通过参数提供的
        存储位置。
\end{itemize}


\subsection{特征转码与pooling}
\label{subsec:feature-encoding}
学了词典以后可以用它把图像的特征转码成最终图像表示。
CloudVision目前实现了最简单的基于BoW特征转码，然后用Sum pooling作出直方图。
这个过程把每个特征关键点的描述子分配到字典里的一个码字，
然后通过sum pooling统计一个1 x $K$的向量，也就是BoW图像表示。
BoW表示向量指数表示第$K$个码字在图像出现了多少次，
BoW表示是码字的直方图。

在CloudVision的特征转码与pooling面对了一个值得提的问题，
如果分布式在每个Spark executor执行特征转码都需要同一个字典，
这个词典每次从Hadoop兼容文件系统读取变成了一个IO性能瓶颈。

\subsection*{算法实现}
机器视觉库实现分布式BoW特征转码算法，主要用到Spark的分布式编程模式的map函数
调用自己实现的BoW算法实现。实现细节如下：
\begin{itemize}
  \item 输入和参数 

        特征转码需要两个输入：第一个是Parquet特征文件，第二个是KMeans的词典。
        要求Parquet每一行是一张图像，另外要求有一列叫"features"。KMeans词典由
        上章介绍的机器视觉库词典学习程序生产。

        程序接受的参数如下：
        \begin{itemize}
          \item Parquet特征文件目录，String数据类型，提供特征Parquet文
                件的存储位置。
          \item KMeans模型文件目录，String数据类型，提供词典存储位置。
          \item Parquet BoW图像表示目录，String数据类型，提供Parquet文
                件的存储位置。
        \end{itemize}
  \item 实现方法

       \begin{figure}[h]
          \centering
            \includegraphics[width=0.76\textwidth]{cloudvision-feature-encoding}
          \caption{CloudVision在Spark集群实现BoW特征转码与表示。}
          \label{fig:cloudvision-feature-encoding}
        \end{figure}
        在图\ref{fig:cloudvision-feature-encoding}可以看到基于Spark分布式方式
        实现特征转码与表示。第一步从Hadoop兼容存储读取Parquet格式的图像的特征和KMeans model，这里KMeans model
        是在章\ref{subsec:dict-learning}学习的词典(Visual Codebook)。因为每个执行特征转码的Spark Executor都需要
        用这个词典，可以一次性通过Spark Broadcast变量把词典提前播放的每个Spark Executor的内存，避免每个节点单独从Hadoop
        兼容文件系统读取词典，解决词典读取IO问题。\cite{spark-programming-guide}

        有了词典可以高效分布式执行特征转码过程，使用Spark分布式map操作执行
        BoW表示函数，BoW函数把每个图像特征矩阵变成一个1 x $K$的向量，表示码字的直方图。
        在算法\ref{lst:feature-encoding}可以看到BoW函数核心代码。
        第一行建立Spark KMeansModel。第二行建立一个1 x $K$的向量用来保存BoW表示。
        第三行建立一个循环遍历特征描述矩阵的每个关键点描述子。
        第四行用词典找出离关键点最近的码字。第六行在BoW表示向量
        增加相应的码字的个数。
        \begin{minipage}{\textwidth}
        \begin{lstlisting}[language=Python,
                           basicstyle=\small,
                           numbers=left,
                           showstringspaces=false,
                           caption={BoW特征转码核心代码},
                           label={lst:feature-encoding}]
        model = KMeansModel(dictionary)
        bow = np.zeros(len(dictionary))
        for keypoint_descriptor in feature_matrix:
            k = model.predict(keypoint_descriptor)
            if pooling = "sum":
                bow[k] += 1
        return bow
        \end{lstlisting}
        \end{minipage}

        所有图像map到了图像表示后，使用Parquet格式保存保存到Hadoop兼容的文件系统。这个过程
        所有Spark executor会并行地将本地处理的BoW表示写到持久存储。

      
  \item 输出

        机器视觉库特征转码输出是BoW图像表示的Parquet文件，里面有两列文件名字和BoW图像表示向量，每一行是一张图像。

\end{itemize}


\section{分类器}
\label{sec:cloudvision_classifier}
分类器是多数机器视觉应用的最后一步，通过有标签的训练数据学习分类器的模型，
然后用模型预测未标签的数据的标签或者类别。
在章\ref{subsubsec:classifier}介绍了多个分类器算法，发现SVM是最常用。
无论在人工特征或者深度学习的特征SVM都可以达到比较好的结果。
在\ref{subsec:classifier-training}介绍处理和训练SVM算法分布式实现。
在\ref{subsec:classifier-label}描述SVM的分类算法的分布式实现。


Spark的MLlib已经包括一个binary(single class) SVM分布式分类器实现，
为了不重复发明轮子，CloudVision基于MLlib现有SVM实现开发。
在基于Spark MLlib的SVM开发面对了两个问题：
\begin{itemize}
  \item Spark MLlib只提供binary(single) classifier SVM，不符合多数机器视觉应用场景。Binary SVM限于分类两种类型，
        但是大部分的机器视觉场景有超过两个类型的分类需求。
  \item 基于Spark MLlib监督机器学习算法需要用它定义的格式，训练数据需要是一个Spark LabeledPoint类型的RDD。
        需要分布式预处理特征BoW表示数据。
\end{itemize}

\subsection{SVM分类器训练算法实现}
\label{subsec:classifier-training}
机器视觉库的多类别SVM分类器的训练算法实现，使用多个Spark MLlib的分布式binary SVM分类器
训练。实现细节如下：
\begin{itemize}
  \item 输入和参数

        训练的输入是有Parquet格式有标签的数据集，每一行表示一张图像，
        要求两列：包括标签的文件名字和BoW图像表示向量。
        程序接受的参数如下:
        \begin{itemize}
          \item Parquet训练数据集目录，String数据类型，提供Parquet文件存储位置。
          \item SVM模型目录，String数据类型，提供模型存储位置。
          \item 抽取标签regex，String数据类型，提供能从文件名字抽取标签的regex字符串。
          \item 最多迭代数，Int数据类型，提供SVM算法最多迭代多少次。
        \end{itemize}
        
  \item 实现方法

        CloudVision分类器使用Scala实现，因为Scala可以更紧密地扩展MLlib原有的机器学习方法。
        为了训练分类器首先需要预处理数据，符合机器学习库的要求，然后执行多类别SVM训练算法。


        \begin{figure}[h]
          \centering
            \includegraphics[width=0.60\textwidth]{cloudvision-classifier}
          \caption{CloudVision预处理和训练分类器实现}
          \label{fig:cloudvision-classifier}
        \end{figure}

        实现方法分成两部分，预处理和训练：
        \begin{itemize}
    
            \item 数据预处理

            数据预处理需要从数据集获取类别ID和特征表示，组成一个Spark的LabeledPoint。
            Spark的LabeledPoint格式需要两个变量：类别ID(label)和特征向量(features)。
            类别ID的变量数据类型是Double，必须从零开始算每个整数表述一个独立的类别。
            特征向量变量的数据类型是Spark的org.apache.spark.mllib.linalg.Vector。

            从数据集获取类别ID，在多数数据集可以使用图像文件名字，
            比如在Caltech-256数据集每个图像文件名的格式是\{classid\}\_\{imgid\}.jpg，
            这样可以通过一个regex(正则表达式)从文件名找出类型，
            在Caltech256可以用这个正则表达式\verb|(\d+)_\d+.jpg|
            取出类型ID。

            在图\ref{fig:cloudvision-classifier}可以看到预处理实现方式，
            先从Hadoop兼容文件系统读取BoW特征向量和文件名字的DataFrame。
            然后通过一个分布式map操作，用上面描述的方式把文件名字和BoW变成
            一个RDD of LabeledPoint。


            \item 训练


            训练多类别的SVM分类器方法是每个类别独立训练一个二类分类器。
            假设有$N$个类别，那需要训练$1..N$个二类（binary）SVM分类器。
            在训练第$i$个列别的时候，先需要把数据集里所有不等于$i$的类别设置为$0$，
            然后将数据集里所有等于$i$的列别设置为$1$。这样把问题变成一个
            普通的二类SVM分类器问题。在图\ref{fig:cloudvision-classifier}可以但到最后部分训练的过程。
            在算法\ref{lst:classifier-training}是用pseudocode描述实现方式。
            \begin{lstlisting}[language=Python,
                               basicstyle=\small,
                               numbers=left,
                               showstringspaces=false,
                               caption={SVM多类别分类器训练pseudocode},
                               label={lst:classifier-training}]
            svm_classifiers = []
            for classid in classes:
                binary_label_features = features_bow.map(to_binary_label)
                svm_classifiers.append(SVMWithSGD.train(binary_label_features))
            \end{lstlisting}


        \end{itemize}
  \item 输出

        SVM训练算法的输出是一个模型。
\end{itemize}


\subsection{SVM分类器分类算法实现}
\label{subsec:classifier-label}
学了SVM模型后，可以将模型用来分类物质的数据。这里
描述基于多类别SVM模型的分布式SVM分类实现。
实现细节如下：
\begin{itemize}
  \item 输入和参数

        分类算法需要两个输入：Parquet格式的BoW图像表示文件和学习出来的模型。
        程序介绍如下参数：
        \begin{itemize}
            \item Parquet BoW图像表示目录，String数据类型，提供Parquet文件的存储
                  位置。
            \item SVM模型目录，String数据类型，提供SVM模型的存储位置。
            \item Parquet分类结果目录，String数据类型，提供Parquet文件存储位置。
        \end{itemize}

  \item 实现方法

        多类别SVM分类器，使用$N$个类别的二类分类器
        ，这$N$个分类器是基于\ref{subsec:classifier-training}训练的，
        $N$个列别的分类器中得分最高的分类器是预测到的类别。
        \begin{lstlisting}[language=Python,
                           basicstyle=\small,
                           numbers=left,
                           showstringspaces=false,
                           caption={SVM多类别分类器分类pseudocode},
                           label={lst:classifier-training}]
        scores = []
        for classifier in svm_classifiers:
            score, classid = classifier.predict(features_bow)
            scores.append( (score, classid) )

        return scores.sortByScore.getFirst.getClassid

        \end{lstlisting}


  \item 输出

        分类算法输出是一个有预测类别的Parquet文件，每一行表示一张图像，第一列是图像名字，第二列是类别。
\end{itemize}





